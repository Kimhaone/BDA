{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "babe8af0",
   "metadata": {},
   "source": [
    "### 필수과제\n",
    "- 영화리뷰데이터 네이버 한국어 데이터\n",
    "- 한국어 리뷰를 전처리 진행하고 -> countverctorizer을 사용해서 전처리를 진행해 주세요.\n",
    "- 문자열 자체 전처를 통해서 행렬 만들어줘야 한다.\n",
    "- 이걸 가지고 학습을 할 수 있는 것이고- >실제 x축과 y축에 어떤 것이 들어가서 카운팅이 되는지를 정확히 이해해야 한다.\n",
    "\n",
    "- 기본 cv값과\n",
    "- 본인이 전처리한 cv값과\n",
    "- 빈도기반 cv값을\n",
    "\n",
    "- 3가지로 나눠서 카운팅 비교 분석을 진행해 주세요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f27294dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\onlyo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "movie = pd.read_csv('movie_rv.csv')\n",
    "\n",
    "import nltk \n",
    "nltk.download('movie_reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67e50b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import movie_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "743d1e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie=movie.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "becfbe50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: konlpy in c:\\users\\onlyo\\anaconda3\\lib\\site-packages (0.6.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: lxml>=4.1.0 in c:\\users\\onlyo\\anaconda3\\lib\\site-packages (from konlpy) (4.9.1)\n",
      "Requirement already satisfied: JPype1>=0.7.0 in c:\\users\\onlyo\\anaconda3\\lib\\site-packages (from konlpy) (1.4.0)\n",
      "Requirement already satisfied: numpy>=1.6 in c:\\users\\onlyo\\anaconda3\\lib\\site-packages (from konlpy) (1.24.4)\n"
     ]
    }
   ],
   "source": [
    "pip install konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044a95be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "from konlpy.tag import Twitter\n",
    "\n",
    "twt=Twitter()\n",
    "\n",
    "parts =['Noun']\n",
    "all_words = []\n",
    "\n",
    "for n in range(len(movie)):\n",
    "    text = movie['document'].iloc[n]\n",
    "    words = twt.pos(text)\n",
    "    words_arr = []\n",
    "    \n",
    "    for i in words:\n",
    "        if i =='EOS' or i =='':continue\n",
    "        word_tmp = i[0]\n",
    "        part = i[1]\n",
    "        if not (part in parts):continue\n",
    "        words_arr.append(words_arr)\n",
    "    all_words.extend(words_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7050f277",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e149763",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = []\n",
    "parts= ['Josa']\n",
    "for i in range(len(movie)):\n",
    "    text = movie['document'].iloc[i]\n",
    "    words = twt.pos(text)\n",
    "    words_arr =[]\n",
    "    for n in words:\n",
    "        if n =='EOS' or n =='':continue\n",
    "        words_tmp=n[0]\n",
    "        part = n[1]\n",
    "        if not (part in parts):continue\n",
    "        words_arr.append(words_tmp)\n",
    "    all_words.extend(words_arr)\n",
    "print(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68faff0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_features(document, word_features):\n",
    "    word_count = {}\n",
    "    for word in document: \n",
    "        word_count[word] = word_count.get(word,0)+1\n",
    "\n",
    "    features = []\n",
    "    \n",
    "    for word in word_features:\n",
    "        features.append(word_count.get(word,0))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29843900",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer() #기본값\n",
    "\n",
    "# 특성 기반\n",
    "cv1 =CountVectorizer(vocabulary =all_words)\n",
    "\n",
    "# 빈도 기반\n",
    "cv2 = CountVectorizer(max_features=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a04a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "rv_cv =cv.fit_transform(movie)\n",
    "\n",
    "rv_cv1= cv1.fit_transform(movie)\n",
    "\n",
    "rv_cv2= cv2.fit_transform(movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8d2c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cv.get_feature_names_out()[:20])\n",
    "print(cv1.get_feature_names_out()[:20])\n",
    "print(cv2.get_feature_names_out()[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5814a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rv_cv.shape\n",
    "rv_cv1.shape\n",
    "rv_cv2.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
